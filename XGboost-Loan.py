# ðŸ“¦ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import xgboost as xgb

# ðŸ§¾ 1. Ø¯Ø§Ø¯Ù‡â€ŒØ®ÙˆØ§Ù†ÛŒ
df = pd.read_csv("C:/Users/pegahg/Desktop/LoanDefaultPrediction/loan_data_encoded.csv")

# ðŸŽ¯ 2. Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù† Ù‡Ø¯Ù (y) Ùˆ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (X)
X = df.drop("Default", axis=1)
y = df["Default"]

# ðŸ“ 3. Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# âœ‚ï¸ 4. ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

# âš–ï¸ 5. ØªÙ†Ø¸ÛŒÙ… ÙˆØ²Ù† Ø¨Ø±Ø§ÛŒ class imbalance
scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()

# ðŸŒ² 6. Ø³Ø§Ø®Øª Ù…Ø¯Ù„ XGBoost
model_xgb = xgb.XGBClassifier(
    objective="binary:logistic",
    eval_metric="logloss",
    use_label_encoder=False,
    scale_pos_weight=scale_pos_weight,
    learning_rate=0.1,
    max_depth=5,
    n_estimators=100,
    random_state=42
)

# ðŸ‹ï¸â€â™‚ï¸ 7. Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
model_xgb.fit(X_train, y_train)

# ðŸ”® 8. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª
y_pred_prob = model_xgb.predict_proba(X_test)[:, 1]
y_pred_class = (y_pred_prob > 0.5).astype("int32")  # Ø¢Ø³ØªØ§Ù†Ù‡ ØªØµÙ…ÛŒÙ…

# ðŸ“Š 9. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
print("Classification Report:")
print(classification_report(y_test, y_pred_class))

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_class))

print("ROC AUC Score:")
print(roc_auc_score(y_test, y_pred_prob))
